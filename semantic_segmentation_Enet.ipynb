{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing openCV\n",
    "import cv2\n",
    "\n",
    "#Displaying image\n",
    "\n",
    "# image = cv2.imread('test_image.jpg')\n",
    "# cv2.imshow('input_image', image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the image to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanelines_image = np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_conversion= cv2.cvtColor(lanelines_image, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying grayscale image\n",
    "\n",
    "# cv2.imshow('input_image', gray_conversion)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing the image \n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('image.jpg')\n",
    "lanelines_image = np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_conversion= cv2.cvtColor(lanelines_image, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('input_image', blur_conversion)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanelines_image = np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_conversion= cv2.cvtColor(lanelines_image, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_conversion = cv2.Canny(blur_conversion, 50,155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('input_image', canny_conversion)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking the region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge(image):\n",
    "          gray_conversion= cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "          blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0)\n",
    "          canny_conversion = cv2.Canny(blur_conversion, 50,150)\n",
    "          return canny_conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_of_interest(image):\n",
    "        Image_height = image.shape[0]\n",
    "        polygons = np.array([[(200, Image_height), (1100, Image_height), (550, 250)]])\n",
    "        image_mask = np.zeros_like(image)\n",
    "        cv2.fillPoly(image_mask, polygons, 255)\n",
    "        return image_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('image.jpg')\n",
    "lanelines_image = np.copy(image)\n",
    "canny_conversion = canny_edge(lanelines_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('result', reg_of_interest(canny_conversion))\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying bitwise_and\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge(image):\n",
    "         gray_conversion= cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "         blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0)\n",
    "         canny_conversion = cv2.Canny(blur_conversion, 50,150)\n",
    "         return canny_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_of_interest(image):\n",
    "         image_height = image.shape[0]\n",
    "         polygons = np.array([[(200, image_height), (1100, image_height), (551, 250)]])\n",
    "         image_mask = np.zeros_like(image)\n",
    "         cv2.fillPoly(image_mask, polygons, 255)\n",
    "         masking_image = cv2.bitwise_and(image,image_mask)\n",
    "         return masking_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanelines_image = np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_conversion = canny_edge(lanelines_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = reg_of_interest(canny_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('result', cropped_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the Hough transform\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_egde(image):\n",
    "         gray_conversion= cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "         blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0)\n",
    "         canny_conversion = cv2.Canny(blur_conversion, 50,150)\n",
    "         return canny_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_of_interest(image):\n",
    "         image_height = image.shape[0]\n",
    "         polygons = np.array([[(200, image_height), (1100, image_height), (551, 250)]])\n",
    "         image_mask = np.zeros_like(image)\n",
    "         cv2.fillPoly(image_mask, polygons, 255)\n",
    "         masking_image = cv2.bitwise_and(image,image_mask)\n",
    "         return masking_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lines(image, lines):\n",
    "            lines_image = np.zeros_like(image)\n",
    "            if lines is not None:\n",
    "                for line in lines:\n",
    "                    X1, Y1, X2, Y2 = line.reshape(4)\n",
    "                    cv2.line(lines_image, (X1, Y1), (X2, Y2), (255,0,0), 10)\n",
    "            return lines_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanelines_image = np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_conv = canny_edge(lanelines_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = reg_of_interest(canny_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength= 40, maxLineGap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "linelines_image = show_lines(lanelines_image, lane_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('result', linelines_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining with actual image\n",
    "\n",
    "image = cv2.imread('image.jpg')\n",
    "lane_image = np.copy(image)\n",
    "canny = canny_edge(lane_image)\n",
    "cropped_image = reg_of_interest(canny)\n",
    "lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength= 40, maxLineGap=5)\n",
    "line_image = show_lines(lane_image, lines)\n",
    "combine_image = cv2.addWeighted(lane_image, 0.8, line_image, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('result', combine_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect road marking in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization the detected road markings\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coordinates(image, line_parameters):\n",
    "          slope, intercept = line_parameters\n",
    "          y1 = image.shape[0]\n",
    "          y2 = int(y1*(3/5))\n",
    "          x1 = int((y1- intercept)/slope)\n",
    "          x2 = int((y2 - intercept)/slope)\n",
    "          return np.array([x1, y1, x2, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_slope_intercept(image, lines):\n",
    "          left_fit = []\n",
    "          right_fit = []\n",
    "          for line in lines:\n",
    "            x1, y1, x2, y2 = line.reshape(4)\n",
    "            parameter = np.polyfit((x1, x2), (y1, y2), 1)\n",
    "            slope = parameter[0]\n",
    "            intercept = parameter[1]\n",
    "            if slope < 0:\n",
    "              left_fit.append((slope, intercept))\n",
    "            else:\n",
    "              right_fit.append((slope, intercept))\n",
    "          left_fit_average =np.average(left_fit, axis=0)\n",
    "          right_fit_average = np.average(right_fit, axis =0)\n",
    "          left_line =make_coordinates(image, left_fit_average)\n",
    "          right_line = make_coordinates(image, right_fit_average)\n",
    "  \n",
    "          return np.array([left_line, right_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge(image):\n",
    "         gray_coversion= cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "         blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0)\n",
    "         canny_conversion = cv2.Canny(blur_conversion, 50,150)\n",
    "         return canny_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lines(image, lines):\n",
    "          lanelines_image = np.zeros_like(image)\n",
    "          if lines is not None:\n",
    "            for line in lines:\n",
    "              X1, Y1, X2, Y2 = line.reshape(4)\n",
    "              cv2.line(lanelines_image, (X1, Y1), (X2, Y2), (255,0,0), 10)\n",
    "          return lanelines_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_of_interest(image):\n",
    "          image_height = image.shape[0]\n",
    "          polygons = np.array([[(200, image_height), (1100, image_height), (551, 250)]])\n",
    "          image_mask = np.zeros_like(image)\n",
    "          cv2.fillPoly(image_mask, polygons, 255)\n",
    "          masking_image = cv2.bitwise_and(image,image_mask)\n",
    "          return masking_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanelines_image = np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_image = canny_edge(lanelines_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = reg_of_interest(canny_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength= 40, maxLineGap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_lines = average_slope_intercept(lanelines_image, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_image = show_lines(lanelines_image, averaged_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_image = cv2.addWeighted(lanelines_image, 0.8, line_image, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('result', combine_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting road markings in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting road markings in video\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coordinates(image, line_parameters):\n",
    "          try:\n",
    "            slope, intercept = line_parameters\n",
    "          except TypeError:\n",
    "            slope, intercept = 0.001,0\n",
    "          #slope, intercept = line_parameters\n",
    "          y1 = image.shape[0]\n",
    "          y2 = int(y1*(3/5))\n",
    "          x1 = int((y1- intercept)/slope)\n",
    "          x2 = int((y2 - intercept)/slope)\n",
    "          return np.array([x1, y1, x2, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_slope_intercept(image, lines):\n",
    "          left_fit = []\n",
    "          right_fit = []\n",
    "          for line in lines:\n",
    "            x1, y1, x2, y2 = line.reshape(4)\n",
    "            parameter = np.polyfit((x1, x2), (y1, y2), 1)\n",
    "            slope = parameter[0]\n",
    "            intercept = parameter[1]\n",
    "            if slope < 0:\n",
    "              left_fit.append((slope, intercept))\n",
    "            else:\n",
    "              right_fit.append((slope, intercept))\n",
    "          left_fit_average =np.average(left_fit, axis=0)\n",
    "          right_fit_average = np.average(right_fit, axis =0)\n",
    "          left_line =make_coordinates(image, left_fit_average)\n",
    "          right_line = make_coordinates(image, right_fit_average)\n",
    "  \n",
    "          return np.array([left_line, right_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge(image):\n",
    "         gray_conversion= cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "         blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0)\n",
    "         canny_conversion = cv2.Canny(blur_conversion, 50,150)\n",
    "         return canny_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lines(image, lines):\n",
    "          line_image = np.zeros_like(image)\n",
    "          if lines is not None:\n",
    "            for line in lines:\n",
    "              x1, y1, x2, y2 = line.reshape(4)\n",
    "              cv2.line(line_image, (x1, y1), (x2, y2), (255,0,0), 10)\n",
    "          return line_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_of_interest(image):\n",
    "          image_height = image.shape[0]\n",
    "          polygons = np.array([[(200, image_height), (1100, image_height), (550, 250)]])\n",
    "          image_mask = np.zeros_like(image)\n",
    "          cv2.fillPoly(image_mask, polygons, 255)\n",
    "          masking_image = cv2.bitwise_and(image,image_mask)\n",
    "          return masking_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiran/anaconda3/envs/selfdriving/lib/python3.8/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/kiran/anaconda3/envs/selfdriving/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) /tmp/pip-req-build-99ib2vsi/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-cc0759d873ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m             \u001b[0mcanny_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanny_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0mcropped_canny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_of_interest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanny_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHoughLinesP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_canny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLineLength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxLineGap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-831a2362f31c>\u001b[0m in \u001b[0;36mcanny_edge\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcanny_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m          \u001b[0mgray_conversion\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m          \u001b[0mblur_conversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_conversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m          \u001b[0mcanny_conversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCanny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur_conversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          \u001b[0;32mreturn\u001b[0m \u001b[0mcanny_conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.4.0) /tmp/pip-req-build-99ib2vsi/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "while(cap.isOpened()):\n",
    "            _, frame = cap.read()\n",
    "            canny_image = canny_edge(frame)\n",
    "            cropped_canny = reg_of_interest(canny_image)\n",
    "            lines = cv2.HoughLinesP(cropped_canny, 2, np.pi/180, 100,             np.array([]), minLineLength=40,maxLineGap=5)\n",
    "            averaged_lines = average_slope_intercept(frame, lines)\n",
    "            line_image = show_lines(frame, averaged_lines)\n",
    "            combo_image = cv2.addWeighted(frame, 0.8, line_image, 1, 1)\n",
    "            cv2.imshow(\"result\", combo_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "cap.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfdriving",
   "language": "python",
   "name": "selfdriving"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
